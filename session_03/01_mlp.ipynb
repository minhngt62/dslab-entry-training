{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfbdf73",
   "metadata": {},
   "source": [
    "# MLP\n",
    "A notebook about MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273751f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Tensorflow is required\n",
    "import tensorflow as tf\n",
    "\n",
    "# Common imports\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "PRJ_ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1f5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "NOTE_ROOT_DIR = os.path.abspath('')\n",
    "DATA_DIR = os.path.join(NOTE_ROOT_DIR, \"data\", \"20news-bydate\")\n",
    "CHAPTER_ID = \"01_mlp\"\n",
    "IMAGES_PATH = os.path.join(NOTE_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c319a",
   "metadata": {},
   "source": [
    "## 1 - Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d545767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data reader (so-called data loader)\n",
    "from models import DataReader\n",
    "with open(os.path.join(DATA_DIR, \"words_idfs.txt\")) as f:\n",
    "    vocab_size = len(f.read().splitlines())\n",
    "\n",
    "def load_dataset():\n",
    "    test_data_reader = DataReader(\n",
    "        data_path=os.path.join(DATA_DIR, \"data_tf_idf.txt\"),\n",
    "        batch_size=50,\n",
    "        vocab_size=vocab_size,\n",
    "        size=(0.8, 1)\n",
    "    )\n",
    "    train_data_reader = DataReader(\n",
    "        data_path=os.path.join(DATA_DIR, \"data_tf_idf.txt\"),\n",
    "        batch_size=50,\n",
    "        vocab_size=vocab_size\n",
    "    )\n",
    "    return train_data_reader, test_data_reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be496b2",
   "metadata": {},
   "source": [
    "## 2 - MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3b5fc",
   "metadata": {},
   "source": [
    "### Pre-setup the Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e0116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters\n",
    "def save_parameters(name, value, epoch):\n",
    "    filename = name.replace(\":\", '-colon-') + '-epoch-{}.txt'.format(epoch)\n",
    "    if len(value.shape) == 1:\n",
    "        string_form = \",\".join([str(number) for number in value])\n",
    "    else:\n",
    "        string_form = '\\n'.join([\",\".join([str(number) for number in value[row]]) for row in range(value.shape[0])])\n",
    "    with open(os.path.join(NOTE_ROOT_DIR, \"data\", \"saved-paras\", filename), \"w\") as f:\n",
    "        f.write(string_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49334876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the parameters\n",
    "def restore_parameter(name, epoch):\n",
    "    filename = name.replace(\":\", '-colon-') + '-epoch-{}.txt'.format(epoch)\n",
    "    with open(os.path.join(NOTE_ROOT_DIR, \"data\", \"saved-paras\", filename)) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    if len(lines) == 1:\n",
    "        value = [float(number) for number in lines[0].split(\",\")]\n",
    "    else:\n",
    "        value = [[float(number) for number in lines[row].split(\",\")] for row in range(len(lines))]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc65ae6",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3791e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build computation graph\n",
    "from models import MLP\n",
    "mlp = MLP(vocab_size=vocab_size, hidden_size=50)\n",
    "pred_y, loss = mlp.build_graph()\n",
    "train_op = mlp.trainer(loss=loss, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c7facef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100, loss: 0.0\n",
      "Step: 200, loss: 0.0\n",
      "Step: 300, loss: 0.0\n",
      "Step: 400, loss: 0.009043372236192226\n",
      "Step: 500, loss: 4.296870974940248e-05\n",
      "Step: 600, loss: 1.3999577276990749e-05\n",
      "Step: 700, loss: 5.72202543480671e-06\n",
      "Step: 800, loss: 7.326543709496036e-06\n",
      "Step: 900, loss: 7.779447514622007e-06\n",
      "Step: 1000, loss: 9.196145401801914e-05\n",
      "Step: 1100, loss: 4.005397897799412e-07\n",
      "Step: 1200, loss: 4.29153317327291e-08\n",
      "Step: 1300, loss: 1.311299229200813e-07\n",
      "Step: 1400, loss: 7.210942385427188e-06\n",
      "Step: 1500, loss: 3.5545549508242402e-06\n",
      "Step: 1600, loss: 8.081491978373379e-05\n",
      "Step: 1700, loss: 1.5974009670571832e-07\n",
      "Step: 1800, loss: 1.192092646817855e-08\n",
      "Step: 1900, loss: 1.430510998545742e-08\n",
      "Step: 2000, loss: 3.337858700547258e-08\n",
      "Step: 2100, loss: 4.124606789446261e-07\n",
      "Step: 2200, loss: 5.555075404117815e-07\n",
      "Step: 2300, loss: 0.0\n",
      "Step: 2400, loss: 0.0\n",
      "Step: 2500, loss: 0.0\n",
      "Step: 2600, loss: 0.0\n",
      "Step: 2700, loss: 0.0\n",
      "Step: 2800, loss: 0.0\n",
      "Step: 2900, loss: 0.0\n",
      "Step: 3000, loss: 0.0\n",
      "Step: 3100, loss: 0.0\n",
      "Step: 3200, loss: 0.0\n",
      "Step: 3300, loss: 0.0\n",
      "Step: 3400, loss: 2.527221738546359e-07\n",
      "Step: 3500, loss: 0.0\n",
      "Step: 3600, loss: 7.15255632499634e-09\n",
      "Step: 3700, loss: 1.1920899112283223e-07\n",
      "Step: 3800, loss: 1.335140495939413e-07\n",
      "Step: 3900, loss: 1.192089627011228e-07\n",
      "Step: 4000, loss: 0.3197338879108429\n",
      "Step: 4100, loss: 0.0\n",
      "Step: 4200, loss: 0.0\n",
      "Step: 4300, loss: 0.0\n",
      "Step: 4400, loss: 0.0\n",
      "Step: 4500, loss: 1.7144503593444824\n",
      "Step: 4600, loss: 1.2159320306182053e-07\n",
      "Step: 4700, loss: 0.003990383818745613\n",
      "Step: 4800, loss: 2.384185515680315e-09\n",
      "Step: 4900, loss: 2.384185515680315e-09\n",
      "Step: 5000, loss: 0.0\n",
      "Step: 5100, loss: 0.33692675828933716\n",
      "Step: 5200, loss: 9.059899497287915e-08\n",
      "Step: 5300, loss: 1.668929172637945e-08\n",
      "Step: 5400, loss: 2.145766764272139e-08\n",
      "Step: 5500, loss: 3.0994389277338996e-08\n",
      "Step: 5600, loss: 2.384185515680315e-09\n",
      "Step: 5700, loss: 0.00011891774920513853\n",
      "Step: 5800, loss: 0.0\n",
      "Step: 5900, loss: 0.0\n",
      "Step: 6000, loss: 0.0\n",
      "Step: 6100, loss: 0.0\n",
      "Step: 6200, loss: 0.0\n",
      "Step: 6300, loss: 0.0\n",
      "Step: 6400, loss: 0.0\n",
      "Step: 6500, loss: 0.0\n",
      "Step: 6600, loss: 0.0\n",
      "Step: 6700, loss: 0.0\n",
      "Step: 6800, loss: 0.0\n",
      "Step: 6900, loss: 0.0\n",
      "Step: 7000, loss: 0.0\n",
      "Step: 7100, loss: 0.0\n",
      "Step: 7200, loss: 0.0\n",
      "Step: 7300, loss: 0.0\n",
      "Step: 7400, loss: 0.0\n",
      "Step: 7500, loss: 0.0\n",
      "Step: 7600, loss: 0.0\n",
      "Step: 7700, loss: 0.0\n",
      "Step: 7800, loss: 0.0\n",
      "Step: 7900, loss: 0.0\n",
      "Step: 8000, loss: 0.0\n",
      "Step: 8100, loss: 0.0\n",
      "Step: 8200, loss: 0.0\n",
      "Step: 8300, loss: 0.0\n",
      "Step: 8400, loss: 0.0\n",
      "Step: 8500, loss: 0.0\n",
      "Step: 8600, loss: 0.0\n",
      "Step: 8700, loss: 0.0\n",
      "Step: 8800, loss: 0.0\n",
      "Step: 8900, loss: 0.0\n",
      "Step: 9000, loss: 0.0\n",
      "Step: 9100, loss: 0.0\n",
      "Step: 9200, loss: 0.0\n",
      "Step: 9300, loss: 0.0\n",
      "Step: 9400, loss: 0.0\n",
      "Step: 9500, loss: 0.0\n",
      "Step: 9600, loss: 0.0\n",
      "Step: 9700, loss: 0.0\n",
      "Step: 9800, loss: 0.0\n",
      "Step: 9900, loss: 0.0\n",
      "Step: 10000, loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Open a session to train the model\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    train_data_reader, test_data_reader = load_dataset()\n",
    "    step, MAX_STEP = 0, 10000\n",
    "    \n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    while step < MAX_STEP:\n",
    "        train_data, train_labels = train_data_reader.next_batch()\n",
    "        plabels_eval, loss_eval, _ = sess.run(\n",
    "            [pred_y, loss, train_op],\n",
    "            feed_dict={\n",
    "                mlp._X: train_data,\n",
    "                mlp._real_Y: train_labels\n",
    "            }\n",
    "        )\n",
    "        step += 1\n",
    "        if step % 100 == 0:\n",
    "            print(\"Step: {}, loss: {}\".format(step, loss_eval))\n",
    "        \n",
    "    trainable_variables = tf.compat.v1.trainable_variables()\n",
    "    for variable in trainable_variables:\n",
    "        save_parameters(\n",
    "            name=variable.name,\n",
    "            value=variable.eval(),\n",
    "            epoch=train_data_reader._num_epoch\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24acfc8d",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cb66c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on the batch 100\n",
      "Test on the batch 200\n",
      "Test on the batch 300\n",
      "Test on the batch 400\n",
      "Test on the batch 500\n",
      "Test on the batch 600\n",
      "Test on the batch 700\n",
      "Test on the batch 800\n",
      "Test on the batch 900\n",
      "Test on the batch 1000\n",
      "Test on the batch 1100\n",
      "Test on the batch 1200\n",
      "Test on the batch 1300\n",
      "Test on the batch 1400\n",
      "Test on the batch 1500\n",
      "Test on the batch 1600\n",
      "Test on the batch 1700\n",
      "Test on the batch 1800\n",
      "Test on the batch 1900\n",
      "Test on the batch 2000\n",
      "Test on the batch 2100\n",
      "Test on the batch 2200\n",
      "Test on the batch 2300\n",
      "Test on the batch 2400\n",
      "Test on the batch 2500\n",
      "Test on the batch 2600\n",
      "Test on the batch 2700\n",
      "Test on the batch 2800\n",
      "Test on the batch 2900\n",
      "Test on the batch 3000\n",
      "========\n",
      "Epoch: 0\n",
      "Accuracy on the test data: 0.2509283819628647\n"
     ]
    }
   ],
   "source": [
    "# Open a session to test the model\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    _, test_data_reader = load_dataset()\n",
    "    step, MAX_STEP = 0, 3000\n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        epoch = 0\n",
    "        trainable_variables = tf.compat.v1.trainable_variables()\n",
    "        for variable in trainable_variables:\n",
    "            saved_value = restore_parameter(\n",
    "                name=variable.name,\n",
    "                epoch=epoch\n",
    "            )\n",
    "            assign_op = variable.assign(saved_value)\n",
    "            sess.run(assign_op)\n",
    "        \n",
    "        num_true_preds = 0\n",
    "        while step < MAX_STEP:\n",
    "            test_data, test_labels = test_data_reader.next_batch()\n",
    "            test_plabels_eval = sess.run(\n",
    "                pred_y,\n",
    "                feed_dict={\n",
    "                    mlp._X: test_data,\n",
    "                    mlp._real_Y: test_labels\n",
    "                }\n",
    "            )\n",
    "            matches = np.equal(test_plabels_eval, test_labels)\n",
    "            num_true_preds += np.sum(matches.astype(\"float\"))\n",
    "            \n",
    "            step += 1\n",
    "            if step % 100 == 0:\n",
    "                print(f\"Test on the batch {step}\")\n",
    "\n",
    "            if test_data_reader._batch_id == 0:\n",
    "                break\n",
    "        \n",
    "        print(\"========\")\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Accuracy on the test data:\", num_true_preds / len(test_data_reader._data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
